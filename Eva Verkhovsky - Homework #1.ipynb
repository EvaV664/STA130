{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4739654c",
   "metadata": {},
   "source": [
    "Question #1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba8d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 866\n",
      "Columns with missing values:\n",
      "Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into a DataFrame\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "\n",
    "# Summarize the total number of missing values\n",
    "total_missing = missing_values.sum()\n",
    "print(f\"Total missing values: {total_missing}\")\n",
    "\n",
    "# Display columns with missing values\n",
    "columns_with_missing = missing_values[missing_values > 0]\n",
    "print(\"Columns with missing values:\")\n",
    "print(columns_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae6567",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/ed1308a0-7bcf-4306-9b35-caac243b6262\n",
    "\n",
    "ChatGPT Session Summary\n",
    "\n",
    "1. Request for a CSV File with Missing Data:\n",
    "\n",
    "Requested a raw CSV file with missing data and a link to such a dataset. A link to the Breast Cancer Wisconsin Dataset was provided.\n",
    "\n",
    "2. Checking for Missing Data:\n",
    "\n",
    "Asked how to see the amount of missing data in a dataset. A Python script using Pandas was provided to check for missing values, calculate percentages, and summarize missing data.\n",
    "\n",
    "3. Error Encountered:\n",
    "\n",
    "Encountered a NameError due to an undefined variable. A revised script was provided to ensure all steps were executed correctly.\n",
    "\n",
    "4. Another Dataset with Missing Values:\n",
    "\n",
    "Since the provided dataset had no missing values, another dataset with known missing values, the Titanic Dataset, was suggested. A Python script for checking missing values in this dataset was also provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67560c0e",
   "metadata": {},
   "source": [
    "Question #2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d63f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891\n",
      "Number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "rows, columns = df.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ddcc5",
   "metadata": {},
   "source": [
    "Definitions:\n",
    "\n",
    "Observations - In the context of the Titanic dataset, an observation refers to a single record or entry in the dataset that represents an individual passenger. Each observation captures all the details about that passenger's journey on the Titanic.\n",
    "\n",
    "Variables - They are the different attributes or pieces of information recorded for each observation in the dataset. They describe the characteristics of the passengers and are represented as columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446c7cb",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/7e114d9b-d479-4cde-b0af-273bc0eebdfa\n",
    " \n",
    "Summary\n",
    "1. Dataset Information:\n",
    "A Titanic dataset was downloaded from Data Science Dojo.\n",
    "The objective was to determine the columns and the amount of data in the dataset.\n",
    "\n",
    "2. Pandas DataFrame Analysis:\n",
    "Python code was provided to load the dataset using Pandas and obtain an overview of the columns and data structure.\n",
    "The code included steps to load the dataset, view column names and data types, check the number of rows and columns, and preview the first few rows.\n",
    "\n",
    "3. Determining Number of Rows and Columns:\n",
    "The .shape attribute of a Pandas DataFrame was used to find the number of rows and columns.\n",
    "\n",
    "4. F-Strings in Python:\n",
    "The f before a string in Python denotes an f-string (formatted string literal), which allows embedding expressions inside string literals using curly braces {}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40abec3c",
   "metadata": {},
   "source": [
    "Question #3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f375e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "Pclass Counts:\n",
      " Pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n",
      "Sex Counts:\n",
      " Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "Embarked Counts:\n",
      " Embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Summary of numeric columns\n",
    "numeric_summary = df.describe()\n",
    "print(numeric_summary)\n",
    "\n",
    "# Count unique values in categorical columns\n",
    "\n",
    "# For the 'Pclass' column (Passenger Class)\n",
    "pclass_counts = df['Pclass'].value_counts()\n",
    "print(\"Pclass Counts:\\n\", pclass_counts)\n",
    "\n",
    "# For the 'Sex' column (Gender)\n",
    "sex_counts = df['Sex'].value_counts()\n",
    "print(\"Sex Counts:\\n\", sex_counts)\n",
    "\n",
    "# For the 'Embarked' column (Port of Embarkation)\n",
    "embarked_counts = df['Embarked'].value_counts()\n",
    "print(\"Embarked Counts:\\n\", embarked_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56421a9",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/5c2a2b57-2d00-405a-b469-d966e40f474d\n",
    "\n",
    "Summary:\n",
    "1. Dataset and Methods Overview:\n",
    "\n",
    "The Titanic dataset, available from this link, was used.\n",
    "To summarize numeric columns, the df.describe() method provides statistics like mean, standard deviation, minimum, and maximum values.\n",
    "To count unique values in categorical columns, the df['column'].value_counts() method is used.\n",
    "\n",
    "2. Steps and Examples:\n",
    "\n",
    "Loading the Dataset: The Titanic dataset is loaded using the appropriate function from Pandas.\n",
    "\n",
    "Summary of Numeric Columns: The df.describe() method provides a summary of numeric columns.\n",
    "\n",
    "Counting Unique Values in Categorical Columns: The df['column'].value_counts() method provides counts of unique values in categorical columns.\n",
    "\n",
    "Example Outputs:\n",
    "\n",
    "The output from df.describe() includes statistical summaries of numeric columns.\n",
    "The df['Pclass'].value_counts() output shows counts of unique passenger classes.\n",
    "The df['Sex'].value_counts() output shows counts of each gender.\n",
    "The df['Embarked'].value_counts() output shows counts of each port of embarkation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5867c1e",
   "metadata": {},
   "source": [
    "Question #4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eba207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (891, 15)\n",
      "Numeric Summary:\n",
      "          survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "Columns in Dataset: Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "Missing Values:\n",
      " survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset\n",
    "dataset_shape = df.shape\n",
    "print(\"Dataset Shape:\", dataset_shape)\n",
    "\n",
    "# Get the summary statistics for numeric columns\n",
    "numeric_summary = df.describe()\n",
    "print(\"Numeric Summary:\\n\", numeric_summary)\n",
    "\n",
    "# Check the columns in the dataset\n",
    "columns = df.columns\n",
    "print(\"Columns in Dataset:\", columns)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02058645",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "1. Number of Columns Analyzed:\n",
    "\n",
    "    - df.shape shows 8 columns in total.\n",
    "    - df.describe() provides summaries for only the numeric columns (age and fare), so it analyzes fewer columns compared to df.shape.\n",
    "\n",
    "2. Values Reported in the \"Count\" Column:\n",
    "\n",
    "    - df.describe() shows counts for numeric columns only.\n",
    "    - For \"age\", the count is 714, indicating that df.describe() includes rows where \"age\" is not missing. The difference between the total number of rows (714) and the count in \"age\" indicates missing values in that column.\n",
    "    - \"fare\" has no missing values (count is 714), so its count matches the total number of rows.\n",
    "\n",
    "Missing values in non-numeric columns (embarked and age) do not affect the df.describe() output but contribute to the discrepancies in counts. This analysis helps explain why the number of columns in df.describe() differs from the total number of columns in df.shape, and why the count of non-missing values may be less than the total number of rows for numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd3445",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/5c2a2b57-2d00-405a-b469-d966e40f474d\n",
    "\n",
    "Summary:\n",
    "\n",
    "1. Dataset Overview:\n",
    "    - The Titanic dataset was used, sourced from this link.\n",
    "    - df.shape showed 714 rows and 8 columns, while df.describe() only included numeric columns (age and fare).\n",
    "\n",
    "2. Discrepancies Between df.shape and df.describe():\n",
    "    - df.describe() excludes non-numeric columns and only shows counts for non-missing numeric values.\n",
    "    - Missing values were present in the age column (177 missing), but not in fare.\n",
    "\n",
    "3. Conclusion:\n",
    "    - The discrepancies arise from missing values in age and the exclusion of non-numeric columns from df.describe()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3795d",
   "metadata": {},
   "source": [
    "Question #5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d63cb2",
   "metadata": {},
   "source": [
    "Explanation by the chatbot:\n",
    "\n",
    "1. Attribute (e.g., df.shape):\n",
    "    - An attribute is like a characteristic or a property of an object. It gives you direct access to some internal information or data about that object.\n",
    "    - In the case of df.shape, it tells you the dimensions of the DataFrame (rows and columns) without performing any additional operation or computation. It doesn't require parentheses () because it's simply returning a stored value, not performing a task.\n",
    "\n",
    "2. Method (e.g., df.describe()):\n",
    "    - A method, on the other hand, is like an action or a function associated with an object. It performs some operation on the object, like computation or transformation.\n",
    "    - df.describe() is a method that computes and returns summary statistics (like mean, count, standard deviation, etc.) for numerical columns in the DataFrame. It requires parentheses because it's actively executing a function.\n",
    "    \n",
    "My own paraphrasing summarization of that difference:\n",
    "\n",
    "- Attributes are like properties that store data and do not need parentheses (e.g., df.shape).\n",
    "- Methods are actions or functions that operate on data and require parentheses to execute (e.g., df.describe())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b3b2b",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/1375d14a-db69-44e0-bbf3-a4bb7240c320\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Discussed the difference between an \"attribute\" and a \"method\" in Python, particularly in the context of DataFrames. Attributes, such as df.shape, are properties that provide stored information about an object and do not require parentheses because they don’t perform any computation. Methods, such as df.describe(), are actions that operate on the object and require parentheses since they involve executing some operation or function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311170d",
   "metadata": {},
   "source": [
    "Question #6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b082706",
   "metadata": {},
   "source": [
    "1. The definitions:\n",
    "    \n",
    "Count: The number of non-null (non-missing) values for each column.\n",
    "\n",
    "Mean: The average value for each column, calculated as the sum of the values divided by the count of values.\n",
    "\n",
    "Standard Deviation (std): A measure of the spread of the values around the mean. It shows how much variation or dispersion exists from the average.\n",
    "\n",
    "Min: The minimum value present in the column.\n",
    "\n",
    "25% (First Quartile): The value below which 25% of the data falls. It’s also called the lower quartile (Q1).\n",
    "\n",
    "50% (Median or Second Quartile): The middle value of the data, such that 50% of the data points are smaller and 50% are larger. It is also referred to as the second quartile.\n",
    "\n",
    "75% (Third Quartile): The value below which 75% of the data falls. It’s also called the upper quartile (Q3).\n",
    "\n",
    "Max: The maximum value present in the column.\n",
    "\n",
    "2. Is it clear what df.describe() does with the data in each columns it analyzes if there is missing data in the column in question?\n",
    "For numerical columns: df.describe() only considers non-null (non-missing) values. It automatically excludes any NaN (Not a Number) values from its calculations. For example, if a column has missing data, the statistics like count, mean, std, etc., will be calculated based on the available non-null values. The count statistic will reflect the number of non-null entries in the column, not the total number of rows.\n",
    "\n",
    "For categorical or non-numerical columns: df.describe() behaves similarly by ignoring missing values when counting the frequency of unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6283a7",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/3e43612f-3942-4757-8d69-74fed84fa538\n",
    "\n",
    "Summary:\n",
    "1. Summary Statistics from df.describe():\n",
    "\n",
    "    - Count: Number of non-null values.\n",
    "    - Mean: Average value.\n",
    "    - Standard Deviation (std): Spread around the mean.\n",
    "    - Min: Minimum value.\n",
    "    - 25%: First quartile.\n",
    "    - 50%: Median.\n",
    "    - 75%: Third quartile.\n",
    "    - Max: Maximum value.\n",
    "\n",
    "2. Handling Missing Data: df.describe() excludes missing values from its calculations, so statistics are based only on non-null entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef243da3",
   "metadata": {},
   "source": [
    "Question #7:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b20445",
   "metadata": {},
   "source": [
    "1) Use Case: Handling Missing Values in a Dataset of customer reviews\n",
    "- The DataFrame, df, includes various columns like CustomerID, ReviewText, Rating, and PurchaseDate.\n",
    "- df.dropna() would remove rows where any column contains NaN. This is useful if I want to ensure that my analysis only includes complete data for all columns.\n",
    "- For example, the Ratings column has many excessive values, if I used del df['Ratings'], I’d remove the entire Ratings column. This might not be desirable if I still need that information for other parts of your analysis.\n",
    "- Conclusion: Use df.dropna() when you want to remove rows with missing values to keep the entire dataset structure intact.Use del df['col'] when you want to permanently remove a specific column from your DataFrame.\n",
    "\n",
    "2) del df['col'] might be preferred over using df.dropna() if you have columns that are no longer relevant or needed for your analysis. Removing unnecessary columns can reduce the memory footprint and simplify your DataFrame. Use Case: You have a dataset with a column that is irrelevant or contains only missing values across all rows, and you want to remove it to simplify the DataFrame or focus on more relevant data.\n",
    "\n",
    "3) By deleting columns that are not relevant to your analysis before applying df.dropna(), you reduce the size of the DataFrame. This means that df.dropna() will only process the columns that are of interest. This can improve performance, especially with large datasets, as it avoids unnecessary operations on columns that won’t be used in the analysis. Also, removing unnecessary columns beforehand helps create a cleaner and more manageable DataFrame.\n",
    "\n",
    "4) Justification for the Approach:\n",
    "- Removing Columns with High Proportion of Missing Values:\n",
    "    - Reason: Columns with a high percentage of missing values may not provide much useful information for the analysis and could skew results. By removing these columns, I streamline the DataFrame and focus on more reliable data.\n",
    "    - Method: I chose to remove columns where more than 50% of the data is missing. This threshold can be adjusted based on the specific requirements and the dataset's context.\n",
    "    \n",
    "- Removing Rows with Remaining Missing Values:\n",
    "    - Reason: After removing irrelevant columns, some rows may still have missing values in the remaining columns. To ensure a complete dataset, these rows are removed.\n",
    "    - Method: df.dropna() is used to remove any rows with missing values after the initial column cleanup.\n",
    "    \n",
    "    Before and After:\n",
    "    - Before: Original shape with all columns.\n",
    "    - After: Reduced shape with complete data in remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9551afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame shape: (891, 12)\n",
      "Initial DataFrame columns: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Columns with missing values: ['Age', 'Cabin', 'Embarked']\n",
      "\n",
      "After cleaning:\n",
      "DataFrame shape: (712, 11)\n",
      "DataFrame columns: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display initial shape and columns\n",
    "print(\"Initial DataFrame shape:\", df.shape)\n",
    "print(\"Initial DataFrame columns:\", df.columns)\n",
    "\n",
    "# Step 1: Remove columns with a large proportion of missing values\n",
    "missing_data = df.isnull().sum()\n",
    "columns_with_missing_data = missing_data[missing_data > 0].index\n",
    "print(\"Columns with missing values:\", columns_with_missing_data.tolist())\n",
    "\n",
    "# Remove columns with missing data (can adjust based on the dataset specifics)\n",
    "for col in columns_with_missing_data:\n",
    "    if df[col].isnull().mean() > 0.5:  # Remove columns with more than 50% missing values\n",
    "        del df[col]\n",
    "\n",
    "# Step 2: Remove rows with any remaining missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display results\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"DataFrame shape:\", df_cleaned.shape)\n",
    "print(\"DataFrame columns:\", df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5d4b9",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/d58b99c9-b9d0-4f84-bcfc-bdb8ace90d1b\n",
    "\n",
    "Summary: \n",
    "1. Use Case for df.dropna() vs. del df['col']:\n",
    "    - df.dropna(): Removes rows with missing values, preserving the dataset structure. Ideal for cleaning data while retaining all columns.\n",
    "    - del df['col']: Removes entire columns. Useful for eliminating irrelevant or redundant data but removes all data within that column.\n",
    "\n",
    "2. Importance of Applying del df['col'] Before df.dropna():\n",
    "    - Efficiency: Removing unnecessary columns first reduces the DataFrame size and computational overhead when applying df.dropna().\n",
    "    - Data Integrity: Ensures df.dropna() only affects relevant columns, preventing loss of valuable data from rows where only irrelevant columns had missing values.\n",
    "\n",
    "3. Cleaning the Titanic Dataset:\n",
    "    - Approach:\n",
    "        1. Load the dataset.\n",
    "        2. Remove columns with more than 50% missing values.\n",
    "        3. Remove rows with any remaining missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858b34e",
   "metadata": {},
   "source": [
    "Question #8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425000a",
   "metadata": {},
   "source": [
    "1) Example: we have dataset with columns Pclass and Age\n",
    "    - df.groupby(\"Pclass\")[\"Age\"].describe(): Groups the data by Pclass and then describes the Age for each group.\n",
    "    - Output: Shows summary statistics (count, mean, std, min, 25%, 50%, 75%, max) for Age within each Pclass group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca0baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "Pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'Pclass' and describe the 'Age' column\n",
    "grouped_describe = df.groupby(\"Pclass\")[\"Age\"].describe()\n",
    "print(grouped_describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e2766",
   "metadata": {},
   "source": [
    "2) The count in df.describe() provides a global perspective, while df.groupby(\"col1\")[\"col2\"].describe() provides group-specific counts, which can differ based on the distribution of missing values across groups. \n",
    "    \n",
    "Why Counts Differ\n",
    "\n",
    "- df.describe() provides a global count across the entire DataFrame for each column, ignoring NaNs in the dataset.\n",
    "- df.groupby(\"col1\")[\"col2\"].describe() provides counts at the group level. If different groups (defined by col1) have different amounts of missing data in col2, each group's count will reflect this variability.\n",
    "\n",
    "Impact of Missing Data:\n",
    "\n",
    "- In df.describe(), the count is affected by the overall presence of missing values in each column.\n",
    "- In df.groupby(\"col1\")[\"col2\"].describe(), the count can vary from group to group, depending on how missing values are distributed among the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6c788",
   "metadata": {},
   "source": [
    "3) Intentionally introducing errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439af98",
   "metadata": {},
   "source": [
    "A. Forgot to include import pandas as pd\n",
    "- The message I received from ChatGPT was \"Make sure you have imported pandas as pd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fcf143",
   "metadata": {},
   "source": [
    "B. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "- The message I received from ChatGPT was \"It looks like there's a small typo in the URL for the Titanic dataset. The correct filename should be titanic.csv rather than titanics.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7823e",
   "metadata": {},
   "source": [
    "C. Try to use a dataframe before it's been assigned into the variable\n",
    "- The message I received from ChatGPT was \"It looks like the code is missing the step to load the data into the DataFrame df. You need to add the line to read the CSV file from the URL into the DataFrame.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277b6f4",
   "metadata": {},
   "source": [
    "D. Forget one of the parentheses somewhere the code\n",
    "- The message I received from ChatGPT was \"It looks like there’s a missing closing parenthesis in the pd.read_csv(url) function call.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1038865",
   "metadata": {},
   "source": [
    "E. Mistype one of the names of the chained functions with the code\n",
    "- The message I received from ChatGPT was \"It looks like there’s a small typo in your variable name. You used grouped_describle instead of grouped_describe, and you're trying to print grouped_describe, which hasn't been defined.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53415f",
   "metadata": {},
   "source": [
    "F. Use a column name that's not in your data for the groupby and column selection\n",
    "- The message I received from ChatGPT was \"It looks like there’s an issue with the column name you're using in the groupby() method. You have \"flower\", but the Titanic dataset has a column named \"Pclass\" for passenger class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bf784",
   "metadata": {},
   "source": [
    "E. Forget to put the column name as a string in quotes for the groupby and column selection\n",
    "- The message I received from ChatGPT was \"The issue in your code is with the syntax used for the groupby() method. The column name Pclass should be provided as a string.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9f729",
   "metadata": {},
   "source": [
    "CONCLUSION: ChatGPT vs Google\n",
    "\n",
    "- I asked ChatGPT to fix errors in my code and he fixed all of them with ease.\n",
    "- It wasn't even necessacery to ask Google or to try and find the errors myself.\n",
    "- I can conclude that ChatGPT is an amazing productivity tool because you don't need to waste time debugging code, it can do it for you, and FAST!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b90c7",
   "metadata": {},
   "source": [
    "Link of Interactive conversation with ChatGPT: https://chatgpt.com/share/bca82441-8d43-4648-830e-92e90c279146\n",
    "\n",
    "Summary:\n",
    "- df.groupby(\"col1\")[\"col2\"].describe(): This method calculates descriptive statistics for col2 within each group defined by col1, showing different statistics for each group.\n",
    "\n",
    "- Difference in Counts: df.describe() shows a global count ignoring missing values, while df.groupby(\"col1\")[\"col2\"].describe() shows counts specific to each group, which can differ based on how missing values are distributed among groups.\n",
    "\n",
    "- Code Fixes: Issues in code included fixing missing parentheses, incorrect column names, and ensuring proper syntax for variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f242f",
   "metadata": {},
   "source": [
    "Question #9 - Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
