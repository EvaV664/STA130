{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1cf941",
   "metadata": {},
   "source": [
    "Question #1:\n",
    "\n",
    "1. The difference between Simple Linear Regression and Multiple Linear Regression; and the benefit the latter provides over the former\n",
    "    - Simple Linear Regression establishes a relationship between a dependent variable and a single independent variable. In contrast, Multiple Linear Regression examines the relationship between a dependent variable and two or more independent variables.\n",
    "    - The main benefit of Multiple Linear Regression is that it allows us to model the effects of multiple factors on the dependent variable, giving a more comprehensive and accurate understanding of the relationship. This can improve the predictive power and reliability of the model, as it accounts for various influences rather than just one. \n",
    "    - In Multiple Linear Regression, you can have multiple continuous variables, multiple indicator variables, or a mix of both.\n",
    "\n",
    "2. The difference between using a continuous variable and an indicator variable in Simple Linear Regression; and these two linear forms\n",
    "    - In Simple Linear Regression, a continuous variable is a variable that can take on a wide range of numerical values (e.g., height, age, income). When a continuous variable is used, the model estimates a slope that represents how changes in this variable affect the dependent variable.\n",
    "    - An indicator variable (or dummy variable), on the other hand, is typically binary, taking values such as 0 or 1 to represent categorical information (e.g., gender, presence/absence). When an indicator variable is used, the model doesn’t produce a continuous slope but rather shifts the dependent variable's mean level based on the category represented.\n",
    "    - Linear forms:\n",
    "        - For a continuous variable X, the model is: Y = β₀ + β₁X + ε where β₁ represents the change in Y for a one-unit increase in X.\n",
    "        - For an indicator variable D, the model is: Y = β₀ + β₁D + ε where β₁ represents the difference in Y between the two categories (e.g., 1 vs. 0) defined by D.\n",
    "\n",
    "3. The change that happens in the behavior of the model (i.e., the expected nature of the data it models) when a single indicator variable is introduced alongside a continuous variable to create a Multiple Linear Regression; and these two linear forms (i.e., the Simple Linear Regression versus the Multiple Linear Regression)\n",
    "    - In a Simple Linear Regression model with only a continuous variable, the equation looks like this: Y = β₀ + β₁X + ε. This model only uses one continuous variable to predict Y. There are no categories or groups involved.\n",
    "    - The new model with both X (continuous) and D (indicator) looks like this: Y = β₀ + β₁X + β₂D + ε. β₀ is still the intercept, but now it’s the intercept specifically when D = 0 (e.g., for males). β₁ is the effect of the continuous variable X (e.g., age), telling us how Y changes as X changes. β₂ adjusts the intercept when D = 1 (e.g., for females). So, it shifts the baseline of Y for one category (D = 1) compared to the other (D = 0).\n",
    "    - Adding D changes the model’s behavior by \n",
    "        - allowing different starting points (intercepts) for different groups (e.g., males and females), even though the effect of X on Y (slope) remains the same.\n",
    "        - predicting Y based on both X and D, so it can handle data where one group might generally have higher or lower Y values than another.\n",
    "\n",
    "4. The effect of adding an interaction between a continuous and an indicator variable in Multiple Linear Regression models; and this linear form\n",
    "    - An interaction term in regression shows how the effect of one variable on the outcome depends on another variable. It’s created by multiplying two variables together and is added to the model to capture combined effects. If the interaction term is significant, it means one variable’s impact on the outcome changes based on the level of the other.\n",
    "    - The linear form of this equation is Y = β0 + β1 * X + β2 * D + β3 * (X * D) + ε. β0 is the intercept for the reference group (D = 0, e.g., males). β1 is the effect of the continuous variable X (e.g., age) on Y (e.g., income) for the reference group. β2 is the shift in the intercept for the other group (D = 1, e.g., females). β3 is the interaction term, adjusting the effect of X when D = 1.\n",
    "\n",
    "5. The behavior of a Multiple Linear Regression model (i.e., the expected nature of the data it models) based only on indicator variables derived from a non-binary categorical variable; this linear form; and the necessarily resulting binary variable encodings it utilizes\n",
    "    - When a model uses only indicator (dummy) variables for a non-binary categorical variable, it models group differences. The expected behavior is that each group will have its own average value of the dependent variable (Y), with these averages represented by different intercepts.\n",
    "    - Example linear form: Y = β₀ + β₁ * D_biology + β₂ * D_english + ε. Where: β₀ is the intercept for the baseline group (e.g., Engineering). β₁ represents the effect for Biology majors compared to the baseline. β₂ represents the effect for English majors compared to the baseline. ε is the error term.\n",
    "    \n",
    "    \n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734bd67-05d8-8002-912d-4635815d9a21\n",
    "\n",
    "Summary of interaction:\n",
    "1. Simple vs. Multiple Linear Regression: Simple linear regression models the relationship between one dependent and one independent variable, while multiple linear regression models the relationship between a dependent variable and multiple independent variables.\n",
    "2. Continuous vs. Indicator Variables: Continuous variables represent numerical data, while indicator variables represent categories as binary (0 or 1).\n",
    "3. Multiple Continuous Variables: Multiple linear regression can include multiple continuous variables, capturing their relationship with the dependent variable.\n",
    "4. Interaction Term: Adding an interaction term between a continuous and an indicator variable in multiple linear regression allows the effect of the continuous variable to vary by the category defined by the indicator.\n",
    "5. Indicator Variables from Non-Binary Categorical Data: A multiple linear regression with indicator variables for a non-binary categorical variable compares the dependent variable's means across different groups, using binary encodings for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a56b09",
   "metadata": {},
   "source": [
    "Question #2:\n",
    "\n",
    "- The outcome variable is the effectiveness of the advertising campaigns. This could be measured in terms of sales, customer engagement, or another metric indicating how well the campaign performs. The predictor variables are the amounts spent on advertising in two different media: TV advertising and online advertising.\n",
    "- The effectiveness of the TV ad might depend on the amount spent on online advertising, and vice versa. This suggests an interaction effect between the two predictor variables (TV ad spend and online ad spend). An interaction occurs when the effect of one predictor variable on the outcome is different depending on the level of another predictor variable.\n",
    "- Without Interaction:\n",
    "    - Continuous predictor variables (TV ad spend and online ad spend): Effectiveness = β₀ + β₁ * TV Ad Spend + β₂ * Online Ad Spend\n",
    "    - Binary predictor variables (high/low TV ad spend and high/low online ad spend): Effectiveness = β₀ + β₁ * TV Ad Spend (high/low) + β₂ * Online Ad Spend (high/low)\n",
    "    - The effect of TV ad spending is assumed to be the same, regardless of how much is spent on online ads, and vice versa. So, the relationship between each type of ad spend and the outcome is considered independently.\n",
    "- With Interaction:\n",
    "    - Continuous predictor variables (TV ad spend and online ad spend): Effectiveness = β₀ + β₁ * TV Ad Spend + β₂ * Online Ad Spend + β₃ * (TV Ad Spend * Online Ad Spend)\n",
    "    - Binary predictor variables (high/low TV ad spend and high/low online ad spend): Effectiveness = β₀ + β₁ * TV Ad Spend (high/low) + β₂ * Online Ad Spend (high/low) + β₃ * (TV Ad Spend (high/low) * Online Ad Spend (high/low))\n",
    "    - The prediction model accounts for the possibility that the relationship between TV ad spending and the effectiveness of the campaign may change depending on the level of online ad spending, and vice versa. This model allows for more flexibility and might provide more accurate predictions if such interactions exist.\n",
    "\n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734c417-5d84-8002-9627-534fbcbb6c1d\n",
    "\n",
    "Summary of interaction:\n",
    "- Advertising Scenario: We discussed how the outcome variable (effectiveness of the campaign) depends on two predictor variables: TV ad spend and online ad spend. We also noted a possible interaction between the two.\n",
    "- Linear Models: I provided formulas for predicting effectiveness, both with and without considering the interaction between the two types of ad spend.\n",
    "- Text Formulas: I gave the formulas in text form as:\n",
    "    - Without Interaction: Effectiveness = β₀ + β₁ * TV Ad Spend + β₂ * Online Ad Spend\n",
    "    - With Interaction: Effectiveness = β₀ + β₁ * TV Ad Spend + β₂ * Online Ad Spend + β₃ * (TV Ad Spend * Online Ad Spend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ff7c7",
   "metadata": {},
   "source": [
    "Question #3:\n",
    "\n",
    "***Attempted to perform multiple linear regression with the help of ChatGPT but I received code with errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad601055",
   "metadata": {},
   "source": [
    "- Intercept: The intercept is extremely large in magnitude (around -20.54), which likely indicates problems with the data or model specification. Normally, the intercept represents the log-odds of the outcome when all predictors are zero, but the size here suggests an unreliable model.\n",
    "\n",
    "- DEMO_gender: The coefficients for different categories of DEMO_gender (e.g., Non-binary, Woman, Unknown) are all very small, and their corresponding standard errors are massive (on the order of millions), indicating potential multicollinearity or data scaling issues.\n",
    "\n",
    "- DEMO_identity_lgbtq: Similarly, the coefficients for the DEMO_identity_lgbtq categories are close to zero with very large standard errors.\n",
    "\n",
    "- DEMO_age: The coefficient for age is -0.5887, which suggests that for each one-year increase in age, the log-odds of being vaccinated decreases by 0.5887. However, given the problematic standard errors, this estimate is not reliable.\n",
    "\n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734cc3c-347c-8002-b103-42d2d314a6bd\n",
    "\n",
    "Summary of interaction:\n",
    "1. You attempted to fit a logistic regression model using DEMO_age, DEMO_gender, and DEMO_identity_lgbtq to predict COVID_vaccinated. The model failed to converge, and the coefficients showed large standard errors.\n",
    "2. I suggested potential issues with multicollinearity and scaling of continuous variables, recommending the use of VIF to check multicollinearity and scaling DEMO_age.\n",
    "3. I recommended using regularized logistic regression (Ridge or Lasso) for better model stability.\n",
    "4. I explained how to get linear predictions (log-odds) and convert them into predicted probabilities using the logistic function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b40714",
   "metadata": {},
   "source": [
    "Question #4:\n",
    "\n",
    "The apparent contradiction:\n",
    "1. R-squared (17.6%) tells you how much of the overall variability in HP the model explains. In your case, it explains a small portion (17.6%), meaning the model isn’t great at predicting HP.\n",
    "2. Coefficients and p-values talk about the relationship between individual predictors (like Sp. Def and Generation) and HP. Even though the model doesn’t explain much of the variability in HP (low R-squared), it can still show that some predictors have a strong relationship with HP (big coefficients and small p-values). This means that these predictors affect HP, but there are other factors at play that aren’t captured in the model, leading to the poor fit overall.\n",
    "\n",
    "- The model may have statistically significant predictors (meaning they affect HP), but it doesn't explain much of the variation in HP (low R-squared).\n",
    "- The strong evidence for the predictors doesn’t mean that the model as a whole does a good job of predicting HP—there might be other important factors missing from the model.\n",
    "\n",
    "\n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734ce1f-ab4c-8002-99dd-baeb242414e8\n",
    "\n",
    "Summary of interaction:\n",
    "- Contradiction in model output: The R-squared value of 17.6% indicates the model explains only a small portion of the variability in HP, while large coefficients with strong statistical significance suggest the predictors (like Special Defense and Generation) are significantly related to HP, but other factors are not captured by the model.\n",
    "- HP: HP stands for Hit Points, a measure of Pokémon health.\n",
    "- Good variance: A high R-squared value indicates a model that explains more of the variability in the outcome. Your model has a low R-squared, suggesting it isn’t great at predicting HP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c708c",
   "metadata": {},
   "source": [
    "Question #5:\n",
    "\n",
    "The five cells of code:\n",
    "1. This code replaces any missing values (NaN) in the pokeaman dataset with the string 'None'. It then calculates the size for a 50% split of the dataset and uses train_test_split from sklearn to randomly divide the dataset into two parts: 50% for training (pokeaman_train) and 50% for testing (pokeaman_test). The random split is made reproducible by setting the random seed to 130. The resulting training data is stored in pokeaman_train.\n",
    "2. This code creates a linear regression model to predict HP based on Attack and Defense using the training data. It then fits the model and displays a summary of the model's performance, including coefficients and statistical metrics.\n",
    "3. This code makes predictions on the test data (pokeaman_test) using the fitted model and calculates two R-squared values:\n",
    "    - 'In-sample' R-squared: The R-squared value for the model's fit on the training data.\n",
    "    - 'Out-of-sample' R-squared: The squared correlation between the actual and predicted HP values on the test data, indicating the model's performance on unseen data.\n",
    "    - For defining the formula for the linear regression model\n",
    "4. This code creates a linear regression model to predict HP using multiple predictors (Attack, Defense, Speed, Legendary, and interaction terms for Sp. Def and Sp. Atk). It then fits the model to the pokeaman_train data and displays a summary of the fitted model, including performance metrics like coefficients and R-squared.\n",
    "5. This code predicts HP values for the test data using the fitted model and calculates two R-squared values:\n",
    "    - 'In-sample' R-squared: The R-squared value for the model's fit on the training data.\n",
    "    - 'Out-of-sample' R-squared: The squared correlation between the actual and predicted HP values on the test data.\n",
    "    - For making predictions and evaluating the model's performance on the test data\n",
    "    \n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734d03b-de48-8002-a949-1be6eebd336b\n",
    "\n",
    "Summary of interaction:\n",
    "1. Train-Test Split: The first code splits the pokeaman dataset into 50% training and 50% testing, replacing missing values in the \"Type 2\" column with 'None'.\n",
    "2. Linear Regression Model: The second code creates a model to predict HP using Attack and Defense, fits it to the training data, and prints a summary of the model.\n",
    "3. R-squared Evaluation: The third code calculates and prints \"in-sample\" and \"out-of-sample\" R-squared values to evaluate the model’s performance.\n",
    "4. Complex Model Formula: The fourth code defines a more complex regression model with multiple interaction terms, fits it, and displays a summary.\n",
    "5. Evaluation for Complex Model: The fifth code evaluates the complex model by predicting test data and calculating R-squared values for both training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34d221",
   "metadata": {},
   "source": [
    "Question #6:\n",
    "\n",
    "The design matrix model4_spec.exog includes the predictor variables used in the regression model, where variables like \"Attack\", \"Defense\", \"Speed\", etc., are transformed (centered and scaled) to standardize their ranges. However, multicollinearity arises when predictors are highly correlated, leading to a high condition number (e.g., 12 trillion). This means the model struggles to estimate unique effects for each predictor. As a result, the model is overfit to the training data and doesn't generalize well to new, unseen data. Even with centering and scaling, multicollinearity can remain, causing poor out-of-sample performance.\n",
    "\n",
    "\n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734d1e9-a354-8002-92a9-874aa097c189\n",
    "\n",
    "Summary of interaction:\n",
    "1. You asked for an explanation of how the design matrix model4_spec.exog is created in a linear model and how multicollinearity contributes to poor out-of-sample predictions.\n",
    "2. I explained that the design matrix contains predictor variables, which are transformed by centering and scaling. Multicollinearity arises when predictors are highly correlated, making it difficult for the model to estimate their unique effects. This leads to a high condition number, indicating instability and poor generalization to new data. Even after centering and scaling, multicollinearity can persist, negatively impacting the model’s ability to make accurate predictions on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a94f4a",
   "metadata": {},
   "source": [
    "Question #7:\n",
    "\n",
    "The models progressively refine the prediction of HP using Pokémon data:\n",
    "\n",
    "1. model5_linear_form: Combines continuous variables (Attack, Speed, etc.) with categorical ones (Generation, Type 1, Type 2) to predict HP.\n",
    "2. model6_linear_form: Adds binary indicator variables for specific Pokémon types and generations to capture their unique effects on HP.\n",
    "3. model7_linear_form: Expands model6 by adding interaction terms between variables (Attack, Speed, etc.) and then scales and centers continuous variables to improve model stability.\n",
    "\n",
    "Each step adds more features and interactions to improve the model’s accuracy and stability.\n",
    "\n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734d2a6-7784-8002-b69a-59ec213c8257\n",
    "\n",
    "Summary of interaction:\n",
    "- You asked for a discussion of how model5_linear_form is extended from model3_fit and model4_fit, followed by how model6_linear_form and model7_linear_form are developed from the previous models. I explained that each model progressively incorporates more features, interactions, and scaling adjustments to improve the prediction of HP in the Pokémon dataset.\n",
    "- Specifically, model5 combines continuous and categorical variables, model6 adds binary indicator variables for specific Pokémon types and generations, and model7 further extends this by introducing interaction terms and applying scaling to continuous predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ecc1d4",
   "metadata": {},
   "source": [
    "Question #8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "580e2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   In Sample Performance (R-squared)  Out of Sample Performance (R-squared)\n",
      "0                           0.803795                               0.802770\n",
      "1                           0.802956                               0.802098\n",
      "2                           0.815657                               0.782063\n",
      "3                           0.806726                               0.799407\n",
      "4                           0.818208                               0.780445\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic dataset with stronger relationships\n",
    "np.random.seed(0)  # For reproducibility of synthetic data\n",
    "\n",
    "# Create independent variables\n",
    "energy = np.random.rand(500)      # Random values between 0 and 1\n",
    "loudness = np.random.rand(500)    # Random values between 0 and 1\n",
    "mode = np.random.randint(0, 2, 500)  # Random 0s and 1s (binary variable)\n",
    "\n",
    "# Create a dependent variable with a linear relationship to energy, loudness, and mode\n",
    "# Adding some noise to make the data more realistic\n",
    "danceability = 0.5 * energy + 0.3 * loudness + 0.2 * mode + np.random.normal(0, 0.1, 500)\n",
    "\n",
    "# Construct the DataFrame\n",
    "songs = pd.DataFrame({\n",
    "    'danceability': danceability,\n",
    "    'energy': energy,\n",
    "    'loudness': loudness,\n",
    "    'mode': mode\n",
    "})\n",
    "\n",
    "# Define the linear model formula\n",
    "linear_form = 'danceability ~ energy * loudness + energy * mode'\n",
    "\n",
    "# Create empty lists to store the R-squared values\n",
    "in_sample_Rsquared = []\n",
    "out_of_sample_Rsquared = []\n",
    "\n",
    "# Number of repetitions\n",
    "reps = 100\n",
    "\n",
    "# Loop to run multiple iterations\n",
    "for i in range(reps):\n",
    "    # Randomly split the data (no fixed seed)\n",
    "    songs_training_data, songs_testing_data = train_test_split(songs, train_size=0.6)\n",
    "    \n",
    "    # Fit the linear model to the training data\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=songs_training_data).fit()\n",
    "    \n",
    "    # Store the in-sample R-squared value\n",
    "    in_sample_Rsquared.append(final_model_fit.rsquared)\n",
    "    \n",
    "    # Compute the out-of-sample R-squared using correlation coefficient\n",
    "    out_of_sample_Rsquared.append(np.corrcoef(songs_testing_data.danceability, \n",
    "                                              final_model_fit.predict(songs_testing_data))[0, 1]**2)\n",
    "\n",
    "# Convert the results into a DataFrame for easier handling\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (R-squared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (R-squared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "df.to_csv(\"model_performance.csv\", index=False)\n",
    "\n",
    "# Alternatively, if you want to inspect the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15f8b6",
   "metadata": {},
   "source": [
    "- In-sample R-squared represents the performance of the model on the training data. It shows how much of the variance in the training set the model explains.\n",
    "- Out-of-sample R-squared represents the model's ability to generalize to new, unseen data, which is measured using the testing data (songs_testing_data).\n",
    "- The train_test_split function is used without a fixed random seed, so each iteration will randomly split the data differently. This introduces variability into the results, allowing us to assess how stable the model's performance is across different splits.\n",
    "- Running this process many times (in your case, 100 iterations) gives us an empirical distribution of how the model might perform on unseen data, helping us better understand its reliability.\n",
    "- Overfitting occurs when a model performs well on training data but poorly on testing data. Underfitting happens when it performs poorly on both. Comparing in-sample and out-of-sample performance helps assess generalization, and repeated splits ensure reliable results. A large gap between these metrics suggests the need for model adjustments to improve generalization.\n",
    "\n",
    "Link of interactive conversation with ChatGPT: https://chatgpt.com/share/6734d4a9-71d4-8002-b696-8cf145c1e58e\n",
    "\n",
    "Summary of interaction:\n",
    "1. Code Debugging: We worked on a Python code to assess in-sample and out-of-sample performance, fixing an issue with clustered points in the plot and modifying the code to save results to a CSV file instead of displaying the plot.\n",
    "2. Model Evaluation: I explained overfitting, underfitting, and the purpose of comparing in-sample and out-of-sample performance. You requested a more concise version, which I provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f4341",
   "metadata": {},
   "source": [
    "Question #9:\n",
    "\n",
    "1. This code compares the \"in-sample\" and \"out-of-sample\" R-squared (model performance) for model7:\n",
    "    - Train on Generation 1: Creates model7_gen1_predict_future using only Generation 1 data and fits it.\n",
    "    - Original Model's R-squared:\n",
    "        - Prints model7's in-sample R-squared on the full data.\n",
    "        - Calculates out-of-sample R-squared using test data pokeaman_test.\n",
    "    - Generation 1 Model's R-squared:\n",
    "        - Prints in-sample R-squared for the Generation 1 fit model.\n",
    "        - Computes out-of-sample R-squared for this model on later generations (Generations not equal to 1).\n",
    "    - Purpose: This evaluates whether a model trained on specific data (Generation 1) generalizes well to new data (later generations), helping identify potential overfitting if out-of-sample R-squared is low.\n",
    "    \n",
    "2. The code trains a model using data from Generations 1-5 (model7_gen1to5_predict_future).\n",
    "    - It then computes both in-sample and out-of-sample R-squared for both the original model (on the full data) and the new model (on Generations 1-5).\n",
    "    - The goal is to check how well the model trained on Generations 1-5 generalizes to Generation 6, highlighting potential overfitting or underfitting by comparing the R-squared values.\n",
    "    \n",
    "3. The code compares the performance of two models: one trained on the entire dataset and one trained only on Generation 1 data. \n",
    "    - It calculates R-squared values to measure how well the models fit the training data (in-sample) and how well they generalize to other data (out-of-sample).\n",
    "    - This helps assess whether a model trained on a specific subset (Generation 1) generalizes well to data from other subsets (other generations).\n",
    "    \n",
    "4. A model is trained on data from Generations 1 to 5 (excluding Generation 6).\n",
    "    - In-Sample R-squared (Original Model): Prints the R-squared for the original model (model6) on the training data.\n",
    "    - Out-of-Sample R-squared (Original Model): Prints the R-squared for the original model on the test data (pokeaman_test).\n",
    "    - In-Sample R-squared (Generations 1-5 Model): Prints the R-squared for the model trained on Generations 1 to 5.\n",
    "    - Out-of-Sample R-squared (Generations 1-5 Model on Generation 6 Data): Prints the R-squared for the model trained on Generations 1 to 5, evaluated on Generation 6 data.\n",
    "    - This compares the performance of models trained on different data subsets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
